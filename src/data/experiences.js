import unccTA from "../icons/uncc.png";
import cogoport from "../icons/cogoport_640.png";
import verzeo from "../icons/verzeo.jpg";

const Experiences = [
    {
        "work_url_name": "unccTA",
        "work_title": "University Of North Carolina, Charlotte",
        "work_position": "Graduate Teaching Assistantship",
        "work_location": "Charlotte, USA",
        "start_date": "22/08/2024",
        "end_date": "08/05/2025",
        "image": unccTA,
        "tech_stack": ["JAVA", "Artificial Intelligence"],
        "description": "As a Teaching Assistant, I support Masterâ€™s and PhD students in their Artificial Intelligence coursework, focusing on foundational algorithms such as Breadth-First Search (BFS) and Depth-First Search (DFS). My responsibilities include clarifying complex concepts during office hours, guiding students through assignments and projects, and providing detailed feedback on their work. This role allows me to engage deeply with AI concepts while fostering a collaborative learning environment for advanced students.",
        "links": {
            "web_url": "https://www.charlotte.edu/",
        },
        "major_contributions": [
            {
                "title": "Grading",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": "",
            },
            {
                "title": "Doubt Solving",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": ""
            },
            {
                "title": "Procturing",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": ""
            }
        ],
        "brief":[
            "I began as a Graduate Teaching Assistant under Prof. Dr. Dewan Ahmed in Fall 2024, after completing the course in Spring 2023. My role involves assisting students with coursework, grading, and proctoring exams. I also address queries via email and Zoom and continue this role through Spring 2025."
        ],
        "details": [
            "I began my role as a <highlight>Graduate Teaching Assistant</highlight> under <highlight>Prof. Dr. Dewan Ahmed</highlight> in Fall 2024, after having completed the same course as a student in Spring 2023. My primary responsibilities include conducting office hours to <highlight>assist Masters and PhD.</highlight> students with course-related queries, assignments, projects, grading, and enhancing their conceptual understanding beyond the classroom.",
            "The course covers fundamental algorithms such as <highlight>BFS, DFS, IDS, UCS, and A* search</highlight>, along with problem-solving techniques like the <highlight>N-Queens Problem</highlight>. I also provide additional support to students by addressing their queries via email and Zoom meetings.",
            "Another key aspect of my role involves proctoring exams, where I collaborate with my colleagues to maintain a structured and fair testing environment. Additionally, I assist the professor in preparing <highlight>homework</highlight> questions and <highlight>grading</highlight> assignments to ensure a smooth learning experience for students.",
            "I am continuing in this role through the Spring 2025 semester. Recently, my responsibilities have expanded as I now serve as the <highlight>Head TA</highlight>, where I guide and mentor fellow Teaching Assistants, ensuring effective coordination and support across the course." 
        ]
    },
    {
        "work_url_name": "cogoport",
        "work_title": "COGO FREIGHT PVT. LTD. Chain",
        "work_position": "Associate Software Engineer",
        "work_location": "Mumbai, India",
        "start_date": "27/06/2022",
        "end_date": "02/04/2023",
        "image": cogoport,
        "tech_stack": ["Ruby on Rails", "Go Lang", "Python", "Sidekiq", "React.js", "PostgreSQL"],
        "description": "Spearheaded technology stack expansion by integrating Golang, augmenting product offerings, and amplifying development capabilities.Started my professional carrer with backend technologies and writing CRUD APIs in Ruby on Rails. Learned more about Authorization and Authentication. Paved my way to bigger projects including micro-services and API integrations with third party APIs",
        "links": {
            "web_url": "https://www.cogoport.com",
        },
        "major_contributions": [
            {
                "title": "Dunning",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": "",
            },
            {
                "title": "Incentives",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": ""
            },
            {
                "title": "Ticket Management System",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": ""
            }
        ],
        "brief":[
            "I started my career at Cogoport in June 2022, working with Ruby on Rails, React.js, Kotlin, and AWS. My key contributions include building APIs, database migrations, CRON jobs, and developing the Ticket System microservice in Golang. I also optimized CI/CD pipelines, enhanced system performance, and documented software methodologies."
        ],
        "details": [
            "I began my professional career at Cogoport on June 27, 2022, working with a diverse tech stack that included <highlight>Ruby on Rails</highlight>, <highlight>React.js</highlight>, and Kotlin for product development. The architecture was built on <highlight>AWS</highlight>, with <highlight>Redis</highlight> for caching, <highlight>Sidekiq</highlight> for CRON jobs, and <highlight>Jenkins</highlight> for CI/CD pipelines. Unit testing was implemented using <highlight>R-Spec</highlight>, among other tools. My interest naturally gravitated towards <highlight>backend</highlight> development, where I focused on understanding data flow, system architecture, and business logic integration within APIs.",
            "My first major contribution was to the <highlight>Promotions</highlight> project, where I led manual testing, <highlight>debugging</highlight>, API development in Ruby on Rails, and wrote <highlight>data-cleaning</highlight> scripts to ensure system integrity. Following this, I worked on internal projects like <highlight>Dunning</highlight> and <highlight>Incentives</highlight>, where I handled database <highlight>migrations</highlight>, integrations, and data issue resolution using <highlight>PostgreSQL</highlight>. Additionally, I optimized CRON jobs for better efficiency and worked with <highlight>Python</highlight> to integrate <highlight>Google Firebase</highlight> with our system.",
            "One of my most significant contributions was the <highlight>Ticket System</highlight> project, where I set up the repository for a new <highlight>Golang-based Microservice</highlight> and was announced as <highlight>code-owner</highlight> by my company. This involved architecting resilient Web APIs in Golang to ensure seamless system performance and operational excellence. I also worked with shell scripting using <highlight>Bash</highlight> and <highlight>Vim</highlight> for command-line operations, improving automation workflows.",
            "Beyond technical development, I played a key role in team coordination and documentation. I authored comprehensive technical documentation on software methodologies using <highlight>Confluence</highlight> and <highlight>Notion</highlight>, ensuring smooth knowledge transfer across the team. As the <highlight>Scrum Master</highlight>, I was responsible for conducting daily standups, managing task delegation, tracking progress, and delivering presentations to maintain performance standards via <highlight>JIRA</highlight>. Additionally, I streamlined <highlight>CI/CD</highlight> pipelines through GitLab and GitHub, enhancing workflow efficiency and facilitating smooth code integration."
        ]
    },
    {
        "work_url_name": "verzeo",
        "work_title": "Verzeo",
        "work_position": "Internship",
        "work_location": "Remote",
        "start_date": "01/07/2020",
        "end_date": "01/09/2020",
        "image": verzeo,
        "tech_stack": ["Python", "Pandas", "Numpy", "Seaborn", "TFIDF"],
        "description": "Collaborated on a team project by scraping web data and performing sentiment analysis on twitter data using Pandas, NumPy, and data visualization with Seaborn.Engineered tweet classification utilizing TFIDF methodology to enhance sentiment analysis capabilities.",
        "links": {
            "web_url": "https://learn.verzeo.in/",
        },
        "major_contributions": [
            {
                "title": "Sentiment Analysis",
                "desc": "",
                "start_date": "",
                "end_date": "",
                "work_span": "",
                "web-url": "",
            }
        ],
        "brief": [
            "During my third year of college, I completed an internship where I learned Machine Learning fundamentals through online training. I worked on training a Random Forest Model to recommend movie recommendation, using Pandas, NumPy, and Seaborn for data processing and visualization. I also developed a tweet classification system using TF-IDF to enhance sentiment analysis accuracy."
        ],
        "details": [
            "During my third year of college, I completed an internship where I was introduced to the fundamentals of <highlight>Machine Learning</highlight> through online training sessions.",
            "As part of the internship, I worked on two key projects that allowed me to apply these concepts in practical scenarios.",
            "For the first project, I worked with a team to develop a <highlight>Random Forest</highlight>-based Movie Recommendation System.",
            "We began by <highlight>scraping</highlight> data from the IMDb website, followed by preprocessing it using <highlight>NumPy</highlight> and <highlight>Pandas</highlight>. The model was trained based on movie genres to generate personalized recommendations for viewers.",
            "To better understand the data and optimize model training, we used <highlight>Seaborn</highlight> for visualization, analyzing the distribution of key parameters to enhance performance.",
            "In the second project, we developed a tweet categorization application using <highlight>Sentiment Analysis</highlight> to categorize tweets as good or negative, hence improving the company's social media analytical skills.",
            "We utilized the <highlight>TF-IDF (Term Frequency-Inverse Document Frequency)</hightlight> method to convert text data into numerical features, which improved the accuracy of our sentiment analysis model.",
            "This project not only strengthened my understanding of <highlight>Natural Language Processing</highlight> but also gave me hands-on experience in building machine learning models for real-world applications.",
        ]
    }
]

export default Experiences;